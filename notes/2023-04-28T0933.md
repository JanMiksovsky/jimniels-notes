# [Jaron Lanier Interview With The Guardian](https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane)

> “This idea of [AI] surpassing human ability is silly because it’s made of human abilities.” [Lanier] says comparing ourselves with AI is the equivalent of comparing ourselves with a car. “It’s like saying a car can go faster than a human runner. Of course it can, and yet we don’t say that the car has become a better runner.”

Humans are special, we too easily forget that. Lanier:

> A lot of modern enlightenment thinkers and technical people feel that there is something old-fashioned about believing that people are special – for instance that consciousness is a thing. They tend to think there is an equivalence between what a computer could be and what a human brain could be. We have to say consciousness is a real thing and there is a mystical interiority to people that’s different from other stuff because if we don’t say people are special, how can we make a society or make technologies that serve people?

Also, this part reminded me about [what Chris Coyier wrote](https://chriscoyier.net/2023/04/21/the-secret-list-of-websites/) on how Google, once the bastion of pointing people to invididual websites, now seems keen on using AI to simply suck up the knowledge on individual websites and spit out a word smoothie _rather_ than send people to your website.

> There are two ways this could go. One is that we pretend the bot is a real thing, a real entity like a person, then in order to keep that fantasy going we’re careful to forget whatever source texts were used to have the bot function. Journalism would be harmed by that. The other way is you do keep track of where the sources came from. And in that case a very different world could unfold where if a bot relied on your reporting, you get payment for it, and there is a shared sense of responsibility and liability where everything works better.

Lanier’s warning on the ultimate danger of AI:

> To me the danger is that we’ll use our technology to become mutually unintelligible

(Found via [Eric Bailey’s excellent links newsletter](https://buttondown.email/ericwbailey/archive/sc-244-test/).)